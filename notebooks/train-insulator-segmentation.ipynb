{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["%env SM_FRAMEWORK=tf.keras\n","\n","import segmentation_models as sm\n","\n","from segmentation_models.utils import set_trainable\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers.legacy import Adam, SGD\n","\n","import numpy as np \n","import os\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n","import matplotlib.pyplot as plt\n","import cv2\n","import time\n","from keras.callbacks import ModelCheckpoint, CSVLogger"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def adjust_data(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img = img / 255\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        for i in range(num_class):\n","            new_mask[mask == i,i] = 1\n","        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n","        mask = new_mask\n","    elif(np.max(img) > 1):\n","        img = img / 255\n","        mask = mask /255\n","        mask[mask >= 0.5] = 1\n","        mask[mask < 0.5] = 0\n","    return (img,mask)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_generator(batch_size, \n","                   train_path,\n","                   image_folder,\n","                   mask_folder,\n","                   aug_dict,\n","                   image_color_mode = \"grayscale\",\n","                   mask_color_mode = \"grayscale\", \n","                   image_save_prefix  = \"image\", \n","                   mask_save_prefix  = \"mask\",\n","                   flag_multi_class = False,\n","                   num_class = 1,\n","                   save_to_dir = None,\n","                   target_size = (width_size,height_size),\n","                   seed = 1):\n","    '''\n","    Can generate image and mask at the same time. Use the same seed for image_datagen and mask_datagen to ensure \n","    the transformation for image and mask is the same. If you want to visualize the results of generator, set \n","    save_to_dir = \"your path\"\n","    '''\n","    \n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    \n","    image_generator = image_datagen.flow_from_directory(train_path,\n","                                                        classes = [image_folder],\n","                                                        class_mode = None,\n","                                                        color_mode = image_color_mode,\n","                                                        target_size = target_size,\n","                                                        batch_size = batch_size,\n","                                                        save_to_dir = save_to_dir,\n","                                                        save_prefix  = image_save_prefix,\n","                                                        seed = seed)\n","    \n","    mask_generator = mask_datagen.flow_from_directory(train_path,\n","                                                        classes = [mask_folder],\n","                                                        class_mode = None,\n","                                                        color_mode = mask_color_mode,\n","                                                        target_size = target_size,\n","                                                        batch_size = batch_size,\n","                                                        save_to_dir = None,\n","                                                        save_prefix  = mask_save_prefix,\n","                                                        seed = seed)\n","    \n","    train_generator = zip(image_generator, mask_generator)\n","    \n","    for (img,mask) in train_generator:\n","        img,mask = adjust_data(img, mask, flag_multi_class, num_class)\n","        yield (img,mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_generator(batch_size,\n","                  test_path,\n","                  image_folder,\n","                  mask_folder,\n","                  image_color_mode = \"grayscale\",\n","                  mask_color_mode = \"grayscale\",\n","                  image_save_prefix  = \"image\",\n","                  mask_save_prefix  = \"mask\",\n","                  flag_multi_class = False,\n","                  num_class = 1, \n","                  save_to_dir = None,\n","                  target_size = (width_size,height_size), seed = 2):\n","    '''\n","    Can generate image and mask at the same time. Use the same seed for image_datagen and mask_datagen to ensure \n","    the transformation for image and mask is the same. If you want to visualize the results of generator, set \n","    save_to_dir = \"your path\"\n","    '''\n","    \n","    image_datagen = ImageDataGenerator()\n","    mask_datagen = ImageDataGenerator()\n","    \n","    image_generator = image_datagen.flow_from_directory(test_path,\n","                                                        classes = [image_folder],\n","                                                        class_mode = None,\n","                                                        color_mode = image_color_mode,\n","                                                        target_size = target_size,\n","                                                        batch_size = batch_size,\n","                                                        save_to_dir = save_to_dir,\n","                                                        save_prefix  = image_save_prefix,\n","                                                        seed = seed)\n","    \n","    mask_generator = mask_datagen.flow_from_directory(test_path,\n","                                                      classes = [mask_folder],\n","                                                      class_mode = None,\n","                                                      color_mode = mask_color_mode,\n","                                                      target_size = target_size,\n","                                                      batch_size = batch_size,\n","                                                      save_to_dir = save_to_dir,\n","                                                      save_prefix  = mask_save_prefix,\n","                                                      seed = seed)\n","    \n","    test_generator = zip(image_generator, mask_generator)\n","    \n","    for (img,mask) in test_generator:\n","        img,mask = adjust_data(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_dataset = '../dataset_insulators/'\n","train_data_path = '../dataset_insulators/train/images'\n","test_data_path = '../dataset_insulators/validation/images/'\n","\n","num_of_imgs_train = sum(len(files) for _, _, files in os.walk(train_data_path))\n","num_of_imgs_test = sum(len(files) for _, _, files in os.walk(test_data_path))\n","\n","num_of_train_samples = int(num_of_imgs_train)\n","num_of_validation_samples  = int(num_of_imgs_test)\n","\n","print(\"Train Images : \", num_of_train_samples)\n","print(\"Validation Images  : \", num_of_validation_samples)\n","\n","batch_size = 2\n","train_samples = num_of_train_samples\n","test_samples = num_of_validation_samples\n","steps_p_epoch = int(train_samples / batch_size)\n","val_steps = int(test_samples / batch_size)\n","nr_epochs = 250"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_Unet_resnet34 = sm.Unet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=1, activation='sigmoid')\n","model_Linknet_resnet34 = sm.Linknet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=1, activation='sigmoid')\n","model_Unet_vgg16 = sm.Unet(backbone_name='vgg16', encoder_weights='imagenet', encoder_freeze=True, classes=1, activation='sigmoid')\n","model_Linknet_vgg16 = sm.Linknet(backbone_name='vgg16', encoder_weights='imagenet', encoder_freeze=True, classes=1, activation='sigmoid')\n","\n","all_models = [model_Unet_resnet34, model_Linknet_resnet34, model_Unet_vgg16, model_Linknet_vgg16]\n","all_names_models = [\"model_Unet_resnet34\", \"model_Linknet_resnet34\", \"model_Unet_vgg16\", \"model_Linknet_vgg16\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for index in range(len(all_names_models)):\n","    since = time.time()\n","    BACKBONE = all_names_models[index].split('_')[-1]\n","    DECODER = all_names_models[index].split('_')[-2]\n","    \n","    preprocess_input = sm.get_preprocessing(BACKBONE)\n","\n","    trainGene = train_generator(batch_size, \n","                               path_dataset, \n","                               'train',\n","                               'mask_train',\n","                               data_gen_args,\n","                               save_to_dir = None, \n","                               image_color_mode = \"rgb\"\n","                              )\n","\n","    testGene = test_generator(batch_size, \n","                              path_dataset,\n","                              'validation', \n","                              'mask_validation', \n","                              save_to_dir = None,\n","                              image_color_mode = \"rgb\")\n","    \n","    model = all_models[index]\n","    opt = Adam(learning_rate=1e-3)\n","\n","    model.compile(opt,\n","                  loss=sm.losses.jaccard_loss,\n","                  metrics=[sm.metrics.IOUScore(threshold=0.5),\n","                  sm.metrics.FScore(threshold=0.5), \n","                  sm.metrics.precision])\n","\n","    csv_logger = CSVLogger(BACKBONE + \"_\" + DECODER + \".csv\", append=True)\n","    \n","    model_checkpoint = ModelCheckpoint(BACKBONE + \"_\" + DECODER + \".hdf5\", \n","                                       monitor='loss',\n","                                       verbose=1,\n","                                       save_best_only=True)\n","    \n","    history = model.fit(trainGene, \n","                        validation_data = testGene,\n","                        validation_steps = val_steps,\n","                        steps_per_epoch = steps_p_epoch,\n","                        epochs=nr_epochs,\n","                        callbacks=[model_checkpoint, csv_logger])\n","    \n","    time_elapsed = time.time() - since\n","    print(\n","        f\"\\n Total time: {round(time_elapsed // 60, 2)} minutes and {round(time_elapsed % 60, 2)} seconds\"\n","    )\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
