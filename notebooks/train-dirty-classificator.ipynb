{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd88ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_size = 512\n",
    "height_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee70e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_custom_model(classes=4):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(width_size, height_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(classes=4):\n",
    "    \n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(width_size, height_size, 3))\n",
    "    base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "    dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "    prediction_layer = layers.Dense(classes, activation='softmax')\n",
    "\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        #dense_layer_1,\n",
    "        #dense_layer_2,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(x, filter):\n",
    "    x_skip = x\n",
    "   \n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    \n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def identity_block(x, filter):\n",
    "\n",
    "    x_skip = x\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9361be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet34(classes = 4):\n",
    "\n",
    "    x_input = tf.keras.layers.Input((width_size, height_size, 3))\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    block_layers = [3, 4, 6, 3]\n",
    "    filter_size = 64\n",
    "\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "                \n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirty_insulator = '../dataset_dirty_insulator/train/'\n",
    "test_size = 0.20\n",
    "batch_size = 4\n",
    "nr_epochs = 50\n",
    "num_of_imgs_train = sum(len(files) for _, _, files in os.walk(dataset_dirty_insulator))\n",
    "num_of_imgs_validation = int(num_of_imgs_train * test_size)\n",
    "steps_p_epoch = int(num_of_imgs_train / batch_size)\n",
    "val_steps = int((num_of_imgs_validation) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63888c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(num_of_imgs_train, steps_p_epoch, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = vgg16()\n",
    "model_resnet = ResNet34()\n",
    "model_custom = define_custom_model()\n",
    "\n",
    "all_models = [model_vgg16, model_resnet, model_custom]\n",
    "all_names_models = [\"model_vgg16\"]\n",
    "#all_names_models = [\"model_vgg16\", \"model_resnet\", \"model_custom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45327cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        validation_split=test_size,\n",
    "    )\n",
    "trainGene = train_datagen.flow_from_directory(\n",
    "    dataset_dirty_insulator,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(width_size, height_size),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "evaluate = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "validation_dataset=evaluate.flow_from_directory('../dataset_dirty_insulator/test/', \n",
    "                                         target_size = (width_size, height_size), batch_size = batch_size,\n",
    "                                         class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cb36f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(len(all_names_models)):\n",
    "    since = time.time()\n",
    " \n",
    "    model = all_models[index]\n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=tf.keras.losses.categorical_crossentropy, \n",
    "                  metrics=['accuracy']),\n",
    "    \n",
    "    csv_logger = CSVLogger(f\"{all_names_models[index]}.csv\", append=True)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(f'{all_names_models[index]}.hdf5',\n",
    "                                       monitor='loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True)\n",
    "    \n",
    "    history = model.fit(trainGene, \n",
    "                    validation_steps = val_steps,\n",
    "                    steps_per_epoch = steps_p_epoch,\n",
    "                    epochs=nr_epochs,\n",
    "                    callbacks=[model_checkpoint, csv_logger])\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print(\n",
    "        f\"\\n Total time: {round(time_elapsed // 60, 2)} minutes and {round(time_elapsed % 60, 2)} seconds\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533abe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(os.listdir('../dataset_dirty_insulator/test/'))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69191ce8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../../neural_network/experimentos/classificator/dataset_inteiro/256/model_vgg16.hdf5\")\n",
    "\n",
    "dict_models = {\"0\": \"soot\",\n",
    "               \"1\": 'excrement', \n",
    "               \"2\": 'clean', \n",
    "               \"3\": 'salt',\n",
    "               }\n",
    "\n",
    "dirty_translate = {\"cinzas_vulcanicas\": \"soot\",\n",
    "               \"dejetos\": 'excrement', \n",
    "               \"limpo\": 'clean', \n",
    "               \"sal\": 'salt',\n",
    "               }\n",
    "\n",
    "results = []\n",
    "\n",
    "path_dirt = '../dataset_dirty_insulator/test/'\n",
    "\n",
    "for dirty in os.listdir(path_dirt):\n",
    "    for idx, file in enumerate(os.listdir(f\"{path_dirt}{dirty}\")):\n",
    "        file_name = f\"{path_dirt}{dirty}/{file}\"\n",
    "\n",
    "        img = cv2.imread(file_name)\n",
    "            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        images = np.vstack([x])\n",
    "\n",
    "        pred = list(model.predict(images, batch_size=batch_size, verbose = 0)[0])\n",
    "        pred = dict_models[f'{pred.index(max(pred))}']\n",
    "         \n",
    "        results.append({\n",
    "            \"name_file\": file_name,\n",
    "            \"category_pred\": pred\n",
    "        })\n",
    "\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Category: {dirty_translate[dirty]}\\nPrediction: {pred}\".upper())\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'./results/256/{dirty}/{file}')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dbf133f",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568da817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models = {\"soot\": \"0\",\n",
    "               \"excrement\": \"1\",\n",
    "               \"clean\": \"2\",\n",
    "               \"salt\": \"3\",\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['soot', 'excrement', 'clean', 'salt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb1258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_weights_models = [\"../../neural_network/experimentos/classificator/dataset_inteiro/256/model_vgg16.hdf5\"]\n",
    "\n",
    "for index_models in range(len(all_weights_models)):\n",
    "    \n",
    "    model = tf.keras.models.load_model(all_weights_models[index_models]) \n",
    "    pred_arrays = []\n",
    "\n",
    "    for index in range(len(validation_dataset.filepaths)):\n",
    "        #print(validation_dataset.filepaths[index])\n",
    "\n",
    "        img = cv2.imread(validation_dataset.filepaths[index])\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        images = np.vstack([x])\n",
    "\n",
    "        pred = list(model.predict(images, batch_size=batch_size, verbose = 0)[0])\n",
    "        pred_arrays.append(pred.index(max(pred)))\n",
    "        #print(pred)\n",
    "\n",
    "    print(all_weights_models[index_models])    \n",
    "    ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_arrays, validation_dataset.classes), display_labels=dict_models).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1317eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true: np.array, y_pred: np.array, classes: list, title: str =\"Confusion Matrix\", cmap: plt = plt.cm.Purples, save_as: str = \"fig.png\") -> plt.subplot:\n",
    "        \"\"\"Plot a consfusion matrix with all classes, considering the y_true and y_pred of the models \n",
    "        Args:\n",
    "            y_true (np.array): True answers about the results\n",
    "            y_pred (np.array): Prediction of the model\n",
    "            classes (list): List with all the classes names\n",
    "            title (str, optional): A text to be the title of plot. Defaults to \"Confusion Matrix\".\n",
    "            cmap (plt, optional): Type of colors to fill the table. Defaults to plt.cm.Purples.\n",
    "            save_as (str, optional): The name so save  the plots. Defaults to \"fig.png\".\n",
    "        Returns:\n",
    "            plt.subp\"lot: Return a a subplot of confusion matrix, \n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "            yticks=np.arange(cm.shape[0]),\n",
    "            xticklabels=classes, yticklabels=classes,\n",
    "            title=title,\n",
    "            ylabel='True',\n",
    "            xlabel='Predicted')\n",
    "\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                rotation_mode=\"anchor\")\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], '.2f'),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(save_as)\n",
    "\n",
    "        return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "pred_models = []\n",
    "\n",
    "evaluate = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "validation_dataset=evaluate.flow_from_directory('../dataset_dirty_insulator/test/', \n",
    "                                         target_size = (width_size, height_size), batch_size = batch_size,\n",
    "                                         class_mode = 'categorical')\n",
    "\n",
    "all_weights_models = [\"../../neural_network/experimentos/classificator/dataset_inteiro/256/model_vgg16.hdf5\"]\n",
    "\n",
    "for index_models in range(len(all_weights_models)):\n",
    "    \n",
    "    model = tf.keras.models.load_model(all_weights_models[index_models]) \n",
    "    pred_arrays = []\n",
    "\n",
    "    for index in range(len(validation_dataset.filepaths)):\n",
    "        #print(validation_dataset.filepaths[index])\n",
    "\n",
    "        img = cv2.imread(validation_dataset.filepaths[index])\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        images = np.vstack([x])\n",
    "\n",
    "        pred_models.append(list(model.predict(images, batch_size=batch_size, verbose = 0)[0]))\n",
    "\n",
    "        pred = list(model.predict(images, batch_size=batch_size, verbose = 0)[0])\n",
    "        pred_arrays.append(pred.index(max(pred)))\n",
    "        \n",
    "\n",
    "    \n",
    "    values = multilabel_confusion_matrix(pred_arrays, validation_dataset.classes)\n",
    "    print(accuracy_score(pred_arrays, validation_dataset.classes))\n",
    "    for index in range(len(values)):\n",
    "        tp, fn = values[index][0]\n",
    "        fp, tn = values[index][1]\n",
    "        \n",
    "    #ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_arrays, validation_dataset.classes), display_labels=validation_dataset.class_indices).plot()\n",
    "    plot_confusion_matrix(pred_arrays, validation_dataset.classes, classes)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
